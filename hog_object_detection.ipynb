{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Models\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_images = glob.glob('./vehicles/vehicles/**/*.png')\n",
    "non_car_images = glob.glob('./non-vehicles/non-vehicles/**/*.png')\n",
    "print('The no of car images is : ' + str(len(car_images)))\n",
    "print('The no of non-car images is : ' + str(len(non_car_images)))\n",
    "print('The total size of the data set is : '+ str(len(car_images)+len(non_car_images)))\n",
    "\n",
    "if(np.absolute(len(car_images)-len(non_car_images))<0.1*(len(car_images)+len(non_car_images))):\n",
    "    print('The Dataset is balanced')\n",
    "else:\n",
    "    print('Data Augmentation is required')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_img = cv2.imread(car_images[np.random.randint(0,len(car_images))])\n",
    "car_img = cv2.cvtColor(car_img,cv2.COLOR_BGR2RGB)\n",
    "non_car_img = cv2.imread(non_car_images[np.random.randint(0,len(non_car_images))])\n",
    "non_car_img = cv2.cvtColor(non_car_img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(car_img)\n",
    "plt.show()\n",
    "plt.imshow(non_car_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    \n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "   \n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    \n",
    "    return hist_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient=9, pix_per_cell=8, cell_per_block=2, \n",
    "                        vis=False, feature_vec=True):\n",
    "    \n",
    "    #If vis is True return the Image to display it\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                                  transform_sqrt=True, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        \n",
    "        return features, hog_image\n",
    "    \n",
    "    \n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                       transform_sqrt=True, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),orient=9,pix_per_cell=8, cell_per_block=2, hog_channel=0):\n",
    "   \n",
    "    features = []\n",
    "    \n",
    "    for file in imgs:\n",
    "        \n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: \n",
    "            feature_image = np.copy(image)      \n",
    "        \n",
    "        # Applying bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        \n",
    "        # Applying color_hist() to get historgram features\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        \n",
    "        #Hog features extraction\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "\n",
    "        \n",
    "        features.append(np.concatenate((spatial_features, hist_features,hog_features)))\n",
    "            \n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visulazing the hog image on car and non-car data\n",
    "car_hog_features,car_hog_image=get_hog_features(car_img[:,:,2], vis=True, feature_vec=True)\n",
    "non_car_hog_features,non_car_hog_image=get_hog_features(non_car_img[:,:,2], vis=True, feature_vec=True)\n",
    "\n",
    "# Visualize \n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7,7))\n",
    "f.subplots_adjust(hspace = .4, wspace=.2)\n",
    "ax1.imshow(car_img)\n",
    "ax1.set_title('Car Image', fontsize=16)\n",
    "ax2.imshow(car_hog_image, cmap='gray')\n",
    "ax2.set_title('Car HOG', fontsize=16)\n",
    "ax3.imshow(non_car_img)\n",
    "ax3.set_title('Non-Car Image', fontsize=16)\n",
    "ax4.imshow(non_car_hog_image, cmap='gray')\n",
    "ax4.set_title('Non-Car HOG', fontsize=16)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HyperParameters for feature Extraction\n",
    "colorspace='YCrCb'\n",
    "spatial_size=(32, 32)\n",
    "hist_bins=32\n",
    "hist_range=(0, 256)\n",
    "orient=9\n",
    "pix_per_cell=8\n",
    "cell_per_block=2\n",
    "hog_channel=0\n",
    "\n",
    "\n",
    "car_features = extract_features(car_images, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel,spatial_size=(32, 32),hist_bins=32, hist_range=(0, 256))\n",
    "not_car_features = extract_features(non_car_images, cspace=colorspace, orient=orient, \n",
    "                        pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel,spatial_size=(32, 32),hist_bins=32, hist_range=(0, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_features=np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "tot_labels=np.hstack((np.ones(len(car_features)), np.zeros(len(not_car_features))))\n",
    "\n",
    "print(tot_features.shape)\n",
    "print(tot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into random train and test sets\n",
    "#Randstate is any number in 0 to 99\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train,X_test,y_train,y_test=train_test_split(tot_features,tot_labels,test_size=0.2,random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler()\n",
    "X_train = X_scaler.fit_transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "svc = LinearSVC()\n",
    "\n",
    "start=time.time()\n",
    "print('Model Training Started')\n",
    "svc.fit(X_train,y_train)\n",
    "print('The testing acuuracy is: '+ str(round(svc.score(X_test,y_test),4)))\n",
    "end=time.time()\n",
    "\n",
    "print('The Time taken for model training and predcition is: '+str(end-start)+ ' s')\n",
    "\n",
    "pickle.dump(svc,open('svc.sav','wb'))\n",
    "svc=pickle.load(open('svc.sav', 'rb'))\n",
    "print('Model is loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classroom code\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins,hog_channel,cspace):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    rectangles=[]\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    \n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "    else: \n",
    "        ctrans_tosearch = np.copy(img_tosearch) \n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    \n",
    "    if(hog_channel=='ALL'):\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "    else:\n",
    "        ch=ctrans_tosearch[:,:,hog_channel]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ctrans_tosearch.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ctrans_tosearch.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    if(hog_channel=='ALL'):\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    else:\n",
    "        hog=get_hog_features(ch, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            if(hog_channel=='ALL'):\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "            else:\n",
    "                hog_features=hog[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel()\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                rectangles.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                \n",
    "    return rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    rects = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        rects.append(bbox)\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image and final rectangles\n",
    "    return img, rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code taken from github https://github.com/jeremy-shannon/CarND-Vehicle-Detection/blob/master/vehicle_detection_project.ipynb\n",
    "\n",
    "\n",
    "def image_pipeline(image):\n",
    "    \n",
    "    colorspace='YCrCb'\n",
    "    spatial_size=(32, 32)\n",
    "    hist_bins=32\n",
    "    hist_range=(0, 256)\n",
    "    orient=9\n",
    "    pix_per_cell=8\n",
    "    cell_per_block=2\n",
    "    hog_channel=0\n",
    "\n",
    "    rectangles = []\n",
    "\n",
    "    ystart = 400\n",
    "    ystop = 464\n",
    "    scale = 1.0\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 416\n",
    "    ystop = 480\n",
    "    scale = 1.0\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 400\n",
    "    ystop = 496\n",
    "    scale = 1.5\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 432\n",
    "    ystop = 528\n",
    "    scale = 1.5\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 400\n",
    "    ystop = 528\n",
    "    scale = 2.0\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 432\n",
    "    ystop = 560\n",
    "    scale = 2.0\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 400\n",
    "    ystop = 596\n",
    "    scale = 3.5\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    ystart = 464\n",
    "    ystop = 660\n",
    "    scale = 3.5\n",
    "    rectangles.append(find_cars(image, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, \n",
    "                                cell_per_block, spatial_size, hist_bins,hog_channel,colorspace))\n",
    "    \n",
    "    rectangles = [item for sublist in rectangles for item in sublist] \n",
    "    \n",
    "    heatmap_img = np.zeros_like(image[:,:,0])\n",
    "    heatmap_img = add_heat(heatmap_img, rectangles)\n",
    "    heatmap_img = apply_threshold(heatmap_img, 1)\n",
    "    labels = label(heatmap_img)\n",
    "    draw_img, rects = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    \n",
    "    \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = mpimg.imread('./test_images/test1.jpg')\n",
    "out_img = image_pipeline(test_img)\n",
    "plt.imshow(out_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=os.listdir(\"test_images/\")\n",
    "for i in images:\n",
    "    image = mpimg.imread('test_images/'+str(i))\n",
    "    result = image_pipeline(image)\n",
    "    mpimg.imsave(\"output_images_hog/\"+str(i), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exeuting the video and saving it to the output folder\n",
    "yellow_output = 'project_video_output_HOG.mp4'\n",
    "clip2 = VideoFileClip('test_video.mp4')\n",
    "yellow_clip = clip2.fl_image(image_pipeline)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
